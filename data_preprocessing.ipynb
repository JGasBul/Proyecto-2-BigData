{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3410f687-74cf-4b83-ad32-6e9eeabd2d0a",
   "metadata": {},
   "source": [
    "# Big Data - Proyecto MLLib\n",
    "# Preprocesamiento de Datos\n",
    "# Inicializar Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f84fd6ff-393f-47c2-8ed6-fd578d42001b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/01 16:12:00 WARN Utils: Your hostname, jgasbul-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "25/06/01 16:12:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/01 16:12:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CARGANDO DATOS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados: 55531 registros, 23 columnas\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Hotel Booking Cancellation - Data Preprocessing\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"=== CARGANDO DATOS ===\")\n",
    "df = spark.read.csv(\"train.csv\", header=True, inferSchema=True)\n",
    "print(f\"Datos cargados: {df.count()} registros, {len(df.columns)} columnas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0249726-fcd4-48fb-a0da-82ab8a339e11",
   "metadata": {},
   "source": [
    "# Definir columnas por tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2757047-0d60-4e6b-aa8a-6a9546770bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas numéricas: 14\n",
      "Columnas categóricas: 7\n",
      "Columnas booleanas: 1\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = [\"lead_time\", \"arrival_date_week_number\", \"stays_in_weekend_nights\", \n",
    "               \"stays_in_week_nights\", \"adults\", \"children\", \"babies\", \n",
    "               \"previous_cancellations\", \"previous_bookings_not_canceled\", \n",
    "               \"booking_changes\", \"days_in_waiting_list\", \"adr\", \n",
    "               \"required_car_parking_spaces\", \"total_of_special_requests\"]\n",
    "\n",
    "categorical_cols = [\"meal\", \"country\", \"market_segment\", \"distribution_channel\", \n",
    "                   \"reserved_room_type\", \"deposit_type\", \"customer_type\"]\n",
    "\n",
    "boolean_cols = [\"is_repeated_guest\"]\n",
    "target_col = \"is_canceled\"\n",
    "\n",
    "print(f\"Columnas numéricas: {len(numeric_cols)}\")\n",
    "print(f\"Columnas categóricas: {len(categorical_cols)}\")\n",
    "print(f\"Columnas booleanas: {len(boolean_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb144d14-5b96-432d-ae20-24790d0b1e83",
   "metadata": {},
   "source": [
    "# 1. TRATAMIENTO DE VALORES NULOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51b149cc-eab0-465c-ae30-4f1be7c34861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRATAMIENTO DE VALORES NULOS ===\n",
      "Mediana de 'children': 0.0\n",
      "Valores nulos después de imputación:\n",
      "+---------+------------------------+-----------------------+--------------------+------+--------+------+----+-------+--------------+--------------------+-----------------+----------------------+------------------------------+------------------+---------------+------------+--------------------+-------------+---+---------------------------+-------------------------+-----------+\n",
      "|lead_time|arrival_date_week_number|stays_in_weekend_nights|stays_in_week_nights|adults|children|babies|meal|country|market_segment|distribution_channel|is_repeated_guest|previous_cancellations|previous_bookings_not_canceled|reserved_room_type|booking_changes|deposit_type|days_in_waiting_list|customer_type|adr|required_car_parking_spaces|total_of_special_requests|is_canceled|\n",
      "+---------+------------------------+-----------------------+--------------------+------+--------+------+----+-------+--------------+--------------------+-----------------+----------------------+------------------------------+------------------+---------------+------------+--------------------+-------------+---+---------------------------+-------------------------+-----------+\n",
      "|        0|                       0|                      0|                   0|     0|       0|     0|   0|     17|             0|                   0|                0|                     0|                             0|                 0|              0|           0|                   0|            0|  0|                          0|                        0|          0|\n",
      "+---------+------------------------+-----------------------+--------------------+------+--------+------+----+-------+--------------+--------------------+-----------------+----------------------+------------------------------+------------------+---------------+------------+--------------------+-------------+---+---------------------------+-------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TRATAMIENTO DE VALORES NULOS ===\")\n",
    "\n",
    "# Imputar valores nulos en 'children' con la mediana\n",
    "children_median = df.approxQuantile(\"children\", [0.5], 0.01)[0]\n",
    "print(f\"Mediana de 'children': {children_median}\")\n",
    "\n",
    "df = df.fillna({\"children\": children_median})\n",
    "\n",
    "# Verificar que no quedan nulos\n",
    "null_counts = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "print(\"Valores nulos después de imputación:\")\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b419c-6d3c-41f5-acf2-1092e3826b75",
   "metadata": {},
   "source": [
    "# 2. INGENIERÍA DE CARACTERÍSTICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25505825-63d7-4656-a4f4-02908b3c7543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== INGENIERÍA DE CARACTERÍSTICAS ===\n",
      "Nuevas características creadas:\n",
      "- total_nights: suma de noches de fin de semana y entre semana\n",
      "- total_guests: suma de adultos, niños y bebés\n",
      "- adr_per_person: ADR por persona\n",
      "- has_special_requests: flag si tiene peticiones especiales\n",
      "- has_previous_cancellations: flag si tiene cancelaciones previas\n",
      "- booking_changes_flag: flag si ha hecho cambios en la reserva\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== INGENIERÍA DE CARACTERÍSTICAS ===\")\n",
    "\n",
    "# Crear nuevas características derivadas\n",
    "df = df.withColumn(\"total_nights\", col(\"stays_in_weekend_nights\") + col(\"stays_in_week_nights\")) \\\n",
    "       .withColumn(\"total_guests\", col(\"adults\") + col(\"children\") + col(\"babies\")) \\\n",
    "       .withColumn(\"adr_per_person\", when(col(\"total_guests\") > 0, col(\"adr\") / col(\"total_guests\")).otherwise(col(\"adr\"))) \\\n",
    "       .withColumn(\"has_special_requests\", when(col(\"total_of_special_requests\") > 0, 1).otherwise(0)) \\\n",
    "       .withColumn(\"has_previous_cancellations\", when(col(\"previous_cancellations\") > 0, 1).otherwise(0)) \\\n",
    "       .withColumn(\"booking_changes_flag\", when(col(\"booking_changes\") > 0, 1).otherwise(0))\n",
    "\n",
    "# Actualizar lista de columnas numéricas\n",
    "numeric_cols_extended = numeric_cols + [\"total_nights\", \"total_guests\", \"adr_per_person\"]\n",
    "binary_derived_cols = [\"has_special_requests\", \"has_previous_cancellations\", \"booking_changes_flag\"]\n",
    "\n",
    "print(\"Nuevas características creadas:\")\n",
    "print(\"- total_nights: suma de noches de fin de semana y entre semana\")\n",
    "print(\"- total_guests: suma de adultos, niños y bebés\")\n",
    "print(\"- adr_per_person: ADR por persona\")\n",
    "print(\"- has_special_requests: flag si tiene peticiones especiales\")\n",
    "print(\"- has_previous_cancellations: flag si tiene cancelaciones previas\")\n",
    "print(\"- booking_changes_flag: flag si ha hecho cambios en la reserva\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83767185-7df3-4af9-82ce-fa0c9a443616",
   "metadata": {},
   "source": [
    "# 3. TRANSFORMACIONES PARA VARIABLES ASIMÉTRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a5e686c-28d4-4c0e-bb94-d97498180156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRANSFORMACIONES PARA VARIABLES ASIMÉTRICAS ===\n",
      "Transformaciones logarítmicas aplicadas a: ['lead_time', 'adr', 'total_of_special_requests']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== TRANSFORMACIONES PARA VARIABLES ASIMÉTRICAS ===\")\n",
    "\n",
    "# Aplicar transformación logarítmica a variables asimétricas\n",
    "skewed_cols = [\"lead_time\", \"adr\", \"total_of_special_requests\"]\n",
    "\n",
    "for col_name in skewed_cols:\n",
    "    df = df.withColumn(f\"{col_name}_log\", \n",
    "                      when(col(col_name) > 0, log(col(col_name) + 1)).otherwise(0))\n",
    "\n",
    "log_transformed_cols = [f\"{col}_log\" for col in skewed_cols]\n",
    "print(f\"Transformaciones logarítmicas aplicadas a: {skewed_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb66a4c-7b73-4477-8a02-5365bf87b455",
   "metadata": {},
   "source": [
    "# 4. DISCRETIZACIÓN DE VARIABLES CONTINUAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2da9e5f9-9411-43a1-a0be-adab568a5725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DISCRETIZACIÓN DE VARIABLES CONTINUAS ===\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== DISCRETIZACIÓN DE VARIABLES CONTINUAS ===\")\n",
    "\n",
    "# Discretizar ADR en rangos\n",
    "adr_bucketizer = Bucketizer(\n",
    "    splits=[-float('inf'), 50, 100, 150, 200, float('inf')],\n",
    "    inputCol=\"adr\",\n",
    "    outputCol=\"adr_bucket\"\n",
    ")\n",
    "\n",
    "# Discretizar lead_time\n",
    "lead_time_bucketizer = Bucketizer(\n",
    "    splits=[-float('inf'), 7, 30, 90, 365, float('inf')],\n",
    "    inputCol=\"lead_time\", \n",
    "    outputCol=\"lead_time_bucket\"\n",
    ")\n",
    "\n",
    "discretized_cols = [\"adr_bucket\", \"lead_time_bucket\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc4b6b-5cbb-4c4e-9dd5-17965fd1856f",
   "metadata": {},
   "source": [
    "# 5. PIPELINE DE TRANSFORMACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2f4acb-f032-4d54-b17d-77b28bffd18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CONSTRUYENDO PIPELINE DE TRANSFORMACIONES ===\n",
      "Pipeline construido con 37 etapas\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== CONSTRUYENDO PIPELINE DE TRANSFORMACIONES ===\")\n",
    "\n",
    "# Imputadores para valores faltantes (por si acaso)\n",
    "imputers = []\n",
    "for col_name in numeric_cols_extended:\n",
    "    imputer = Imputer(\n",
    "        inputCols=[col_name],\n",
    "        outputCols=[f\"{col_name}_imputed\"],\n",
    "        strategy=\"median\"\n",
    "    )\n",
    "    imputers.append(imputer)\n",
    "\n",
    "# StringIndexers para variables categóricas\n",
    "string_indexers = []\n",
    "for col_name in categorical_cols:\n",
    "    indexer = StringIndexer(\n",
    "        inputCol=col_name,\n",
    "        outputCol=f\"{col_name}_indexed\",\n",
    "        handleInvalid=\"keep\"\n",
    "    )\n",
    "    string_indexers.append(indexer)\n",
    "\n",
    "# OneHotEncoders para variables categóricas\n",
    "one_hot_encoders = []\n",
    "indexed_categorical_cols = [f\"{col}_indexed\" for col in categorical_cols]\n",
    "encoded_categorical_cols = [f\"{col}_encoded\" for col in categorical_cols]\n",
    "\n",
    "for i, col_name in enumerate(indexed_categorical_cols):\n",
    "    encoder = OneHotEncoder(\n",
    "        inputCols=[col_name],\n",
    "        outputCols=[encoded_categorical_cols[i]],\n",
    "        handleInvalid=\"keep\"\n",
    "    )\n",
    "    one_hot_encoders.append(encoder)\n",
    "\n",
    "# Escaladores para variables numéricas\n",
    "scaler_cols = [f\"{col}_imputed\" for col in numeric_cols_extended] + log_transformed_cols\n",
    "scaled_cols = [f\"{col}_scaled\" for col in scaler_cols]\n",
    "\n",
    "# Usar StandardScaler\n",
    "assembler_for_scaling = VectorAssembler(\n",
    "    inputCols=scaler_cols,\n",
    "    outputCol=\"features_to_scale\"\n",
    ")\n",
    "\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"features_to_scale\",\n",
    "    outputCol=\"scaled_features\",\n",
    "    withStd=True,\n",
    "    withMean=True\n",
    ")\n",
    "\n",
    "# Separar características escaladas\n",
    "feature_slicer = VectorSlicer(\n",
    "    inputCol=\"scaled_features\",\n",
    "    outputCol=\"numeric_features_scaled\",\n",
    "    indices=list(range(len(scaler_cols)))\n",
    ")\n",
    "\n",
    "# Ensamblar todas las características finales\n",
    "all_feature_cols = [\"numeric_features_scaled\"] + encoded_categorical_cols + boolean_cols + binary_derived_cols + discretized_cols\n",
    "\n",
    "final_assembler = VectorAssembler(\n",
    "    inputCols=all_feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# Construir pipeline completo\n",
    "def create_preprocessing_pipeline():\n",
    "    stages = []\n",
    "    \n",
    "    # Bucketizers\n",
    "    stages.extend([adr_bucketizer, lead_time_bucketizer])\n",
    "    \n",
    "    # Imputadores\n",
    "    stages.extend(imputers)\n",
    "    \n",
    "    # String indexers\n",
    "    stages.extend(string_indexers)\n",
    "    \n",
    "    # One hot encoders\n",
    "    stages.extend(one_hot_encoders)\n",
    "    \n",
    "    # Escalado\n",
    "    stages.extend([assembler_for_scaling, scaler, feature_slicer])\n",
    "    \n",
    "    # Ensamblador final\n",
    "    stages.append(final_assembler)\n",
    "    \n",
    "    return Pipeline(stages=stages)\n",
    "\n",
    "preprocessing_pipeline = create_preprocessing_pipeline()\n",
    "\n",
    "print(f\"Pipeline construido con {len(preprocessing_pipeline.getStages())} etapas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05f4608-9ebd-48bf-bfb8-bfabff7450d3",
   "metadata": {},
   "source": [
    "# 6. APLICAR TRANSFORMACIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3572ba74-3447-4eae-a8bb-3237ee582494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== APLICANDO TRANSFORMACIONES ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/01 16:12:16 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformaciones aplicadas correctamente\n",
      "Dimensiones del vector de características: 224\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== APLICANDO TRANSFORMACIONES ===\")\n",
    "\n",
    "# Fit del pipeline\n",
    "fitted_pipeline = preprocessing_pipeline.fit(df)\n",
    "\n",
    "# Transform\n",
    "df_transformed = fitted_pipeline.transform(df)\n",
    "\n",
    "print(\"Transformaciones aplicadas correctamente\")\n",
    "print(f\"Dimensiones del vector de características: {len(df_transformed.select('features').first()[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43477a1-8b30-4049-99a5-de9a0b5e042c",
   "metadata": {},
   "source": [
    "# 7. DIVISIÓN TRAIN/VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8ecfe9b-fa28-40f8-92e5-84aab153f612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DIVISIÓN TRAIN/VALIDATION ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento: 44413 registros\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 88:=============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de validación: 11118 registros\n",
      "\n",
      "Distribución de clases en entrenamiento:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|is_canceled|count|\n",
      "+-----------+-----+\n",
      "|          1|18486|\n",
      "|          0|25927|\n",
      "+-----------+-----+\n",
      "\n",
      "Distribución de clases en validación:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 94:=============================>                            (1 + 1) / 2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|is_canceled|count|\n",
      "+-----------+-----+\n",
      "|          1| 4627|\n",
      "|          0| 6491|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(\"\\n=== DIVISIÓN TRAIN/VALIDATION ===\")\n",
    "\n",
    "# Dividir en train y validation\n",
    "train_df, val_df = df_transformed.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Conjunto de entrenamiento: {train_df.count()} registros\")\n",
    "print(f\"Conjunto de validación: {val_df.count()} registros\")\n",
    "\n",
    "# Verificar distribución de clases\n",
    "print(\"\\nDistribución de clases en entrenamiento:\")\n",
    "train_df.groupBy(target_col).count().show()\n",
    "\n",
    "print(\"Distribución de clases en validación:\")\n",
    "val_df.groupBy(target_col).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a280d09-5e09-4537-ac8a-03d1be3f0410",
   "metadata": {},
   "source": [
    "# 8. GUARDAR DATOS PREPROCESADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f107e354-1d7d-451c-984c-6a4fe302c1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GUARDANDO DATOS PREPROCESADOS ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos preprocesados guardados:\n",
      "- preprocessing_pipeline/: Pipeline de transformaciones\n",
      "- train_processed/: Datos de entrenamiento procesados\n",
      "- val_processed/: Datos de validación procesados\n",
      "\n",
      "=== RESUMEN DE TRANSFORMACIONES APLICADAS ===\n",
      "1. Imputación de valores nulos en 'children' con mediana\n",
      "2. Creación de características derivadas:\n",
      "   - total_nights, total_guests, adr_per_person\n",
      "   - has_special_requests, has_previous_cancellations, booking_changes_flag\n",
      "3. Transformaciones logarítmicas para variables asimétricas\n",
      "4. Discretización de ADR y lead_time en buckets\n",
      "5. Encoding de variables categóricas con StringIndexer + OneHotEncoder\n",
      "6. Normalización de variables numéricas con StandardScaler\n",
      "7. Ensamblado final de todas las características\n",
      "8. Dimensión final del vector de características: 224\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== GUARDANDO DATOS PREPROCESADOS ===\")\n",
    "\n",
    "# Guardar pipeline fitted para reutilización\n",
    "fitted_pipeline.write().overwrite().save(\"preprocessing_pipeline\")\n",
    "\n",
    "# Guardar datos transformados\n",
    "train_df.select(\"features\", target_col).write.mode(\"overwrite\").parquet(\"train_processed\")\n",
    "val_df.select(\"features\", target_col).write.mode(\"overwrite\").parquet(\"val_processed\")\n",
    "\n",
    "print(\"Datos preprocesados guardados:\")\n",
    "print(\"- preprocessing_pipeline/: Pipeline de transformaciones\")\n",
    "print(\"- train_processed/: Datos de entrenamiento procesados\")\n",
    "print(\"- val_processed/: Datos de validación procesados\")\n",
    "\n",
    "# 9. RESUMEN DE TRANSFORMACIONES\n",
    "print(\"\\n=== RESUMEN DE TRANSFORMACIONES APLICADAS ===\")\n",
    "print(\"1. Imputación de valores nulos en 'children' con mediana\")\n",
    "print(\"2. Creación de características derivadas:\")\n",
    "print(\"   - total_nights, total_guests, adr_per_person\")\n",
    "print(\"   - has_special_requests, has_previous_cancellations, booking_changes_flag\")\n",
    "print(\"3. Transformaciones logarítmicas para variables asimétricas\")\n",
    "print(\"4. Discretización de ADR y lead_time en buckets\")\n",
    "print(\"5. Encoding de variables categóricas con StringIndexer + OneHotEncoder\")\n",
    "print(\"6. Normalización de variables numéricas con StandardScaler\")\n",
    "print(\"7. Ensamblado final de todas las características\")\n",
    "print(f\"8. Dimensión final del vector de características: {len(df_transformed.select('features').first()[0])}\")\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
